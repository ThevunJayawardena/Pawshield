# -*- coding: utf-8 -*-
"""PetSkinDetectionFinalv1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NWY6yx86cd0cIoQ4_b_JriX9tFIiV-J4
"""

from google.colab import drive
drive.mount('/content/drive')

#The imports
import os
import sys
import json
import time
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks, applications
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import traceback

DRIVE_BASE_PATH = "/content/drive/MyDrive/Final Year Project"

DATA_DIR = os.path.join(DRIVE_BASE_PATH, "New Dataset")
MODEL_SAVE_DIR = os.path.join(DRIVE_BASE_PATH, "Models")
TREATMENT_JSON_PATH = os.path.join(DRIVE_BASE_PATH, "Other", "Treatment.json")
MODEL_INFO_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, "pawshield_model_info.json")

IMG_SIZE = (224, 224)
BATCH_SIZE = 32
LABEL_SMOOTHING = 0.1

DOG_BACKBONE = 'ResNet50V2'
DOG_DENSE = 512
DOG_DROPOUT = 0.4
DOG_L2 = 0.001

CAT_BACKBONE = 'MobileNetV2'
CAT_DENSE = 512
CAT_DROPOUT = 0.4
CAT_L2 = 0.001

DEFAULT_TRANSFER_LR_STAGE1 = 5e-4
DEFAULT_TRANSFER_LR_STAGE2 = 3e-5
DEFAULT_TRANSFER_EPOCHS_STAGE1 = 20
DEFAULT_TRANSFER_EPOCHS_STAGE2 = 50
DEFAULT_TRANSFER_PATIENCE = 12

MEAN_NORM = np.array([0.485, 0.456, 0.406], dtype=np.float32)
STD_NORM = np.array([0.229, 0.224, 0.225], dtype=np.float32)

def preprocess_image(image, label):
    image = tf.image.resize(image, IMG_SIZE)
    image = tf.cast(image, tf.float32)
    image = image / 255.0
    image = (image - MEAN_NORM) / STD_NORM
    return image, label

data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2),
], name="data_augmentation")

def load_dataset(data_subset_dir, subset_name, batch_size=BATCH_SIZE, img_size=IMG_SIZE):

    if not os.path.isdir(data_subset_dir):
         raise ValueError(f"Directory not found: {data_subset_dir}")

    dataset = tf.keras.utils.image_dataset_from_directory(
        data_subset_dir,
        labels='inferred',
        label_mode='categorical',
        image_size=img_size,
        interpolation='nearest',
        batch_size=batch_size,
        shuffle=(subset_name == 'train'),
        seed=123
    )

    _ = next(iter(dataset))

    class_names = dataset.class_names
    num_classes = len(class_names)

    if num_classes == 0:
        raise ValueError(f"No image classes found in {data_subset_dir}. Ensure subdirectories exist.")

    print(f"Found {num_classes} classes: {class_names}")

    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)

    return dataset, class_names

def calculate_class_weights(dataset, num_classes):
    print("Calculating class weights...")
    class_counts = np.zeros(num_classes)
    num_samples = 0
    num_batches = 0

    for _, labels_batch in dataset:
        labels_np = labels_batch.numpy()
        class_indices = np.argmax(labels_np, axis=1)
        counts = np.bincount(class_indices, minlength=num_classes)
        if len(counts) < num_classes:
            counts = np.pad(counts, (0, num_classes - len(counts)), 'constant')
        class_counts += counts
        num_samples += labels_np.shape[0]
        num_batches += 1

    if num_batches == 0 or num_samples == 0:
      return None

    zero_indices = np.where(class_counts == 0)[0]
    if len(zero_indices) > 0:
        class_counts[zero_indices] = 1.0

    class_weights_calculated = num_samples / (num_classes * class_counts)
    class_weights_dict = {i: weight for i, weight in enumerate(class_weights_calculated)}

    return class_weights_dict

def create_hybrid_model(num_classes, input_shape, backbone_name, weights, backbone_trainable, dense_units, dropout_rate, l2_lambda):
    if backbone_name == 'ResNet50V2':
        backbone_class = tf.keras.applications.ResNet50V2
    elif backbone_name == 'MobileNetV2':
        backbone_class = tf.keras.applications.MobileNetV2
    else:
        raise ValueError(f"Unsupported backbone: {backbone_name}")

    backbone = backbone_class(
        include_top=False,
        weights=weights,
        input_shape=input_shape,
        pooling='avg',
    )

    backbone.trainable = backbone_trainable
    actual_backbone_layer_name = backbone.name

    inputs = tf.keras.Input(shape=input_shape, name="input_image")
    x = data_augmentation(inputs)
    x = backbone(x, training=backbone_trainable)

    x = layers.BatchNormalization(name="post_backbone_bn")(x)
    x = layers.Dropout(dropout_rate, name="dropout_1")(x)

    reg = tf.keras.regularizers.l2(l2_lambda) if l2_lambda > 0 else None

    x = layers.Dense(dense_units, name="dense_1", kernel_regularizer=reg)(x)
    x = layers.BatchNormalization(name="dense_1_bn")(x)
    x = layers.Activation('relu', name="dense_1_relu")(x)
    x = layers.Dropout(dropout_rate, name="dropout_2")(x)
    outputs = layers.Dense(num_classes, activation='softmax', name="output_dense")(x)

    model = models.Model(inputs=inputs, outputs=outputs, name=f"PawShield_{backbone_name}")

    return model, actual_backbone_layer_name

def plot_history(history, animal_type_stage, backbone_name):
    acc = history.history.get('accuracy', [])
    val_acc = history.history.get('val_accuracy', [])
    loss = history.history.get('loss', [])
    val_loss = history.history.get('val_loss', [])

    if not acc or not val_acc or not loss or not val_loss:
        return

    epochs = range(1, len(acc) + 1)

    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'bo-', label='Training Accuracy')
    plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.title(f'{animal_type_stage.replace("_", " ").capitalize()} Accuracy ({backbone_name})')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'bo-', label='Training Loss')
    plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
    plt.legend(loc='upper right')
    plt.title(f'{animal_type_stage.replace("_", " ").capitalize()} Loss ({backbone_name})')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)

    plt.tight_layout()
    save_path = os.path.join(MODEL_SAVE_DIR, f'{animal_type_stage}_{backbone_name}_training_history.png')

    plt.savefig(save_path)
    plt.show()

def plot_confusion_matrix(y_true, y_pred_classes, class_names, animal_type_stage, backbone_name):
    if y_true is None or y_pred_classes is None or not hasattr(y_true, '__len__') or len(y_true) == 0 or not hasattr(y_pred_classes, '__len__') or len(y_pred_classes) == 0:
        return
    if not class_names:
        return
    if len(y_true) != len(y_pred_classes):
         return

    num_classes = len(class_names)
    max_pred_index = np.max(y_pred_classes) if len(y_pred_classes) > 0 else -1
    max_true_index = np.max(y_true) if len(y_true) > 0 else -1
    if max_true_index >= num_classes or max_true_index < 0 or max_pred_index >= num_classes or max_pred_index < 0:
       return

    cm = confusion_matrix(y_true, y_pred_classes, labels=np.arange(num_classes))
    plt.figure(figsize=(max(8, num_classes * 0.8), max(6, num_classes * 0.6)))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.title(f'{animal_type_stage.replace("_", " ").capitalize()} Confusion Matrix ({backbone_name})')
    plt.tight_layout()
    save_path = os.path.join(MODEL_SAVE_DIR, f'{animal_type_stage}_{backbone_name}_confusion_matrix.png')

    plt.savefig(save_path)
    plt.show()

def train_animal_model(
    animal_type,
    training_strategy,
    backbone_name,
    img_size,
    batch_size,
    num_epochs_stage1=DEFAULT_TRANSFER_EPOCHS_STAGE1,
    num_epochs_stage2=DEFAULT_TRANSFER_EPOCHS_STAGE2,
    learning_rate_stage1=DEFAULT_TRANSFER_LR_STAGE1,
    learning_rate_stage2=DEFAULT_TRANSFER_LR_STAGE2,
    patience=DEFAULT_TRANSFER_PATIENCE,
    dense_units=512,
    dropout_rate=0.5,
    l2_lambda=0.001,
    label_smoothing=LABEL_SMOOTHING,
    apply_augmentation=True
):
    train_dir = os.path.join(DATA_DIR, "train", animal_type)
    valid_dir = os.path.join(DATA_DIR, "val", animal_type)
    test_dir = os.path.join(DATA_DIR, "test", animal_type)
    input_shape = img_size + (3,)

    train_dataset, class_names = load_dataset(train_dir, "train", batch_size=batch_size, img_size=img_size)
    valid_dataset, _ = load_dataset(valid_dir, "validation", batch_size=batch_size, img_size=img_size)
    test_dataset, test_class_names = load_dataset(test_dir, "test", batch_size=batch_size, img_size=img_size)

    num_classes = len(class_names)

    class_weights = calculate_class_weights(train_dataset, num_classes)

    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                                            patience=max(1, patience // 2),
                                            min_lr=1e-7, verbose=1)
    early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=patience,
                                             restore_best_weights=True, verbose=1)

    model = None
    history = None
    final_history_data = {'loss': [], 'accuracy': [], 'val_loss': [], 'val_accuracy': [], 'lr': []}
    actual_backbone_name = None

    loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)

    if training_strategy == 'transfer':
        model, actual_backbone_name = create_hybrid_model(
            num_classes=num_classes,
            input_shape=input_shape,
            backbone_name=backbone_name,
            weights='imagenet',
            backbone_trainable=False,
            dense_units=dense_units,
            dropout_rate=dropout_rate,
            l2_lambda=l2_lambda
        )
        model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate_stage1),
                      loss=loss_fn,
                      metrics=['accuracy'])

        history_stage1 = model.fit(
            train_dataset,
            epochs=num_epochs_stage1,
            validation_data=valid_dataset,
            class_weight=class_weights,
            verbose=1
        )

        plot_history(history_stage1, f"{animal_type}_{backbone_name}_Transfer_Stage1", backbone_name)

        for key, val in history_stage1.history.items():
            final_history_data[key] = list(val)
        if 'lr' in history_stage1.history:
             final_history_data['lr'] = list(history_stage1.history['lr'])
        else:
             final_history_data['lr'] = [learning_rate_stage1] * len(history_stage1.epoch)

        if actual_backbone_name is None:
             return None, None, None

        backbone_layer = model.get_layer(actual_backbone_name)
        backbone_layer.trainable = True

        model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate_stage2),
                      loss=loss_fn,
                      metrics=['accuracy'])

        total_epochs_overall = num_epochs_stage1 + num_epochs_stage2
        initial_epoch_stage2 = num_epochs_stage1

        history_stage2 = model.fit(
            train_dataset,
            epochs=total_epochs_overall,
            initial_epoch=initial_epoch_stage2,
            validation_data=valid_dataset,
            callbacks=[early_stopping, reduce_lr],
            class_weight=class_weights,
            verbose=1
        )

        for key in final_history_data.keys():
            if key in history_stage2.history:
                final_history_data[key].extend(history_stage2.history[key])
            elif key == 'lr' and 'lr' not in history_stage2.history:
                num_epochs_run_stage2 = len(history_stage2.history.get('loss', []))
                final_history_data[key].extend([learning_rate_stage2] * num_epochs_run_stage2)

    else:
        print(f"Warning: Unsupported training strategy '{training_strategy}'. Model will not be trained.")
        return None, None, None

    class HistoryMock:
        def __init__(self, history_dict):
            self.history = history_dict

    plot_stage_name = f"{animal_type}_{backbone_name}_{training_strategy.capitalize()}_Final"
    plot_history(HistoryMock(final_history_data), plot_stage_name, backbone_name)

    test_loss, test_acc = model.evaluate(test_dataset, verbose=1)

    y_true_list = []
    y_pred_list = []

    for x_batch, y_batch in test_dataset:
        y_pred_batch = model.predict(x_batch, verbose=0)
        y_pred_list.append(y_pred_batch)
        y_true_list.append(y_batch.numpy())

    if y_true_list and y_pred_list:
        y_true = np.concatenate(y_true_list, axis=0)
        y_pred_probs = np.concatenate(y_pred_list, axis=0)
        y_true_classes = np.argmax(y_true, axis=1)
        y_pred_classes = np.argmax(y_pred_probs, axis=1)

        present_labels_indices = sorted(list(set(y_true_classes) | set(y_pred_classes)))
        report_labels = [class_names[i] for i in present_labels_indices if i < len(class_names)]
        report = classification_report(y_true_classes, y_pred_classes, target_names=class_names, zero_division=0)
        print(report)
        present_labels_indices = sorted(list(set(y_true_classes) | set(y_pred_classes)))
        plot_confusion_matrix(y_true_classes, y_pred_classes, class_names, plot_stage_name, backbone_name)

    model_save_path = os.path.join(MODEL_SAVE_DIR, f"{animal_type}_{backbone_name}_{training_strategy.capitalize()}_tf_saved_model.keras")

    model.save(model_save_path)

    return model, class_names, HistoryMock(final_history_data)

def load_treatment_data(json_path):
    try:
        with open(json_path, 'r') as f:
            treatment_data = json.load(f)
        return treatment_data
    except:
        return {}

def default_treatment_message():
    return {
        "description": "Information not available.",
        "symptoms": ["Consult a veterinarian for accurate symptoms."],
        "treatments": ["Please consult with a veterinarian for diagnosis and treatment options."],
        "veterinary_visit": "Recommended"
    }

#Getting the treatment recommandation
def get_treatment_recommendation(animal_type, disease_name, treatment_data):
    animal_key = animal_type.lower()
    disease_key = disease_name.lower().replace(" ", "_").replace("-", "_")

    if not isinstance(treatment_data, dict) or not treatment_data:
        return default_treatment_message()

    animal_treatments = treatment_data.get(animal_key)
    if animal_treatments is None:
        return default_treatment_message()

    if not isinstance(animal_treatments, dict):
         return default_treatment_message()

    specific_treatment = animal_treatments.get(disease_key)
    if specific_treatment is None:
         return default_treatment_message()

    complete_treatment = default_treatment_message()
    complete_treatment.update(specific_treatment)
    return complete_treatment

#For testing purpose
def predict_single_image(image_path, model, class_names, animal_type, treatment_data):
    if not os.path.exists(image_path) or model is None or not class_names:
        print("Invalid input parameters.")
        return

    img = tf.keras.utils.load_img(image_path, target_size=IMG_SIZE)
    img_array = tf.keras.utils.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    img_processed = img_array / 255.0
    img_processed = (img_processed - MEAN_NORM) / STD_NORM

    predictions = model.predict(img_processed, verbose=0)
    probabilities = tf.nn.softmax(predictions[0]).numpy()
    predicted_index = np.argmax(probabilities)

    if predicted_index >= len(class_names):
         print("Invalid prediction index.")
         return

    predicted_class = class_names[predicted_index]
    treatment_info = get_treatment_recommendation(animal_type, predicted_class, treatment_data)

#Main code
if __name__ == "__main__":
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

    treatment_data = load_treatment_data(TREATMENT_JSON_PATH)

    dog_model, dog_classes, dog_history = None, None, None
    cat_model, cat_classes, cat_history = None, None, None

    #Training the dog model
    try:
        dog_model, dog_classes, dog_history = train_animal_model(
            animal_type="Dog",
            training_strategy='transfer',
            backbone_name=DOG_BACKBONE,
            img_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            num_epochs_stage1=DEFAULT_TRANSFER_EPOCHS_STAGE1,
            num_epochs_stage2=DEFAULT_TRANSFER_EPOCHS_STAGE2,
            learning_rate_stage1=DEFAULT_TRANSFER_LR_STAGE1,
            learning_rate_stage2=DEFAULT_TRANSFER_LR_STAGE2,
            patience=DEFAULT_TRANSFER_PATIENCE,
            dense_units=DOG_DENSE,
            dropout_rate=DOG_DROPOUT,
            l2_lambda=DOG_L2,
            label_smoothing=LABEL_SMOOTHING,
            apply_augmentation=True
        )
    except:
        pass
    #Training the cat model
    try:
        cat_model, cat_classes, cat_history = train_animal_model(
            animal_type="Cat",
            training_strategy='transfer',
            backbone_name=CAT_BACKBONE,
            img_size=IMG_SIZE,
            batch_size=BATCH_SIZE,
            num_epochs_stage1=DEFAULT_TRANSFER_EPOCHS_STAGE1,
            num_epochs_stage2=DEFAULT_TRANSFER_EPOCHS_STAGE2,
            learning_rate_stage1=DEFAULT_TRANSFER_LR_STAGE1,
            learning_rate_stage2=DEFAULT_TRANSFER_LR_STAGE2,
            patience=DEFAULT_TRANSFER_PATIENCE,
            dense_units=CAT_DENSE,
            dropout_rate=CAT_DROPOUT,
            l2_lambda=CAT_L2,
            label_smoothing=LABEL_SMOOTHING,
            apply_augmentation=True
        )
    except:
        pass

    final_dog_classes = dog_classes if dog_model is not None else None
    final_cat_classes = cat_classes if cat_model is not None else None

    if final_dog_classes is not None and final_cat_classes is not None:
        model_info = {
            'dog_classes': final_dog_classes,
            'cat_classes': final_cat_classes,
            'img_size': list(IMG_SIZE),
            'mean_norm': MEAN_NORM.tolist(),
            'std_norm': STD_NORM.tolist(),
            'model_configs': {
                 'Dog': {'backbone': DOG_BACKBONE, 'strategy': 'transfer'},
                 'Cat': {'backbone': CAT_BACKBONE, 'strategy': 'transfer'}
            }
        }
        try:
            with open(MODEL_INFO_SAVE_PATH, 'w') as f:
                json.dump(model_info, f, indent=4)
        except:
            pass
    #Testing both the dog and cat model with a single image
    dog_model_load_path = os.path.join(MODEL_SAVE_DIR, f"Dog_{DOG_BACKBONE}_Transfer_tf_saved_model.keras")
    cat_model_load_path = os.path.join(MODEL_SAVE_DIR, f"Cat_{CAT_BACKBONE}_Transfer_tf_saved_model.keras")

    loaded_dog_model = None
    current_dog_classes = None
    if dog_model:
        loaded_dog_model = dog_model
        current_dog_classes = dog_classes
    elif os.path.exists(dog_model_load_path):
        try:
            loaded_dog_model = tf.keras.models.load_model(dog_model_load_path)
            if os.path.exists(MODEL_INFO_SAVE_PATH):
                 with open(MODEL_INFO_SAVE_PATH, 'r') as f:
                    info = json.load(f)
                    current_dog_classes = info.get('dog_classes')
        except:
            loaded_dog_model = None
            current_dog_classes = None

    if loaded_dog_model and current_dog_classes:
        test_dog_image_path = os.path.join(DRIVE_BASE_PATH, "New Dataset/test/Dog/Demodicosis/1-14-_png.rf.c0a3b51c1485e38b3b98c92c367bab09.jpg")
        if os.path.exists(test_dog_image_path):
            predict_single_image(test_dog_image_path, loaded_dog_model, current_dog_classes, "Dog", treatment_data)

    loaded_cat_model = None
    current_cat_classes = None
    if cat_model:
        loaded_cat_model = cat_model
        current_cat_classes = cat_classes
    elif os.path.exists(cat_model_load_path):
        try:
            loaded_cat_model = tf.keras.models.load_model(cat_model_load_path)
            if os.path.exists(MODEL_INFO_SAVE_PATH):
                 with open(MODEL_INFO_SAVE_PATH, 'r') as f:
                    info = json.load(f)
                    current_cat_classes = info.get('cat_classes')
        except:
            loaded_cat_model = None
            current_cat_classes = None

    if loaded_cat_model and current_cat_classes:
        test_cat_image_path = os.path.join(DRIVE_BASE_PATH, "New Dataset/test/Cat/Jamur/JamurRobo-10-_jpg.rf.9759a844c1ee7092a821cee74c3a7cb5.jpg")
        if os.path.exists(test_cat_image_path):
            predict_single_image(test_cat_image_path, loaded_cat_model, current_cat_classes, "Cat", treatment_data)